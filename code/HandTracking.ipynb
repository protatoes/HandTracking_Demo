{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24fbc971-2c3f-4204-ba8f-624427f8392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "from tkinter_webcam import webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488c66a-a398-46fa-ae9a-300ea793453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640) # adjust width\n",
    "cap.set(4,480) # adjust height\n",
    "\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(max_num_hands=4)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "pTime = 0\n",
    "cTime = 0\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img,1)\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)\n",
    "    # print(results.multi_hand_landmarks)\n",
    "    if results.multi_hand_worlandmarks: \n",
    "        for handLMS in results.multi_hand_landmarks:\n",
    "            for id, lm in enumerate(handLMS.landmark):\n",
    "                h,w,c = img.shape\n",
    "                cx,cy = int(lm.x*w),int(lm.y*h)\n",
    "                if id == 4:\n",
    "                    cv2.circle(img,(cx,cy),15,(255,0,255),cv2.FILLED)\n",
    "                \n",
    "            mp_drawing.draw_landmarks(img,handLMS,mpHands.HAND_CONNECTIONS)\n",
    "    \n",
    "    #Get FPS\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime - pTime)\n",
    "    pTime = cTime\n",
    "    \n",
    "    cv2.putText(img,str(int(fps)),(10,70),cv2.FONT_HERSHEY_COMPLEX,3,(255,0,255),3)\n",
    "    \n",
    "    cv2.imshow(\"Webcam\", img) # This will open an independent window\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'): # quit when 'q' is pressed\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "340e4604-44d1-4ad7-8d94-c588055b3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "class handDetector():\n",
    "    def __init__(self,mode=False, maxHands = 2, detectionCon=0.5,trackCon=0.5,model_complexity=0):\n",
    "        #initialize the configuration for mp Hands\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackCon = trackCon\n",
    "        self.model_complexity = model_complexity\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        #Construct the hand detection model\n",
    "        self.hands = self.mpHands.Hands(static_image_mode = self.mode,\n",
    "                                        max_num_hands = self.maxHands,\n",
    "                                        min_detection_confidence = self.detectionCon,\n",
    "                                        min_tracking_confidence = self.trackCon,\n",
    "                                        model_complexity = self.model_complexity)\n",
    "        \n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        \n",
    "    def _get_output_path(self, name):\n",
    "            return os.path.join(tempfile.gettempdir(), self.id().split('.')[-1] + name)\n",
    "\n",
    "    def _landmarks_list_to_array(self, landmark_list, image_shape):\n",
    "        rows, cols, _ = image_shape\n",
    "        return np.asarray([(lmk.x * cols, lmk.y * rows, lmk.z * cols)\n",
    "                        for lmk in landmark_list.landmark])\n",
    "\n",
    "    def _world_landmarks_list_to_array(self, landmark_list):\n",
    "        return np.asarray([(lmk.x, lmk.y, lmk.z)\n",
    "                        for lmk in landmark_list.landmark])\n",
    "\n",
    "\n",
    "    def findHands(self, img,draw = True):\n",
    "        #simple method for finding and displaying a hand on an image\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "        # print(results.multi_hand_landmarks)\n",
    "        if self.results.multi_hand_landmarks: \n",
    "            for handLMS in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mp_drawing.draw_landmarks(img,\n",
    "                                                   handLMS,\n",
    "                                                   self.mpHands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "    \n",
    "    def findPosition(self, img, handID=0, draw = True):\n",
    "        #list will have all the landmark positions\n",
    "        lmList = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handID] #[self.results.multi_hand_landmarks[id] for id in handID]\n",
    "            \n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "                h,w,c = img.shape\n",
    "                cx,cy = int(lm.x*w),int(lm.y*h)\n",
    "                lmList.append([id,cx,cy])\n",
    "                # if id == 4:\n",
    "                if draw:\n",
    "                    cv2.circle(img,(cx,cy),15,(255,0,255),cv2.FILLED)\n",
    "                \n",
    "            \n",
    "        return(lmList)\n",
    "    \n",
    "    def findRealWorldPositions(self, img, handID=0):\n",
    "        lmList = []\n",
    "        if self.results.multi_hand_world_landmarks:\n",
    "            myHand = self.results.multi_hand_world_landmarks[handID]\n",
    "            for id,hand_world_landmarks in enumerate(myHand.landmark):\n",
    "                cx,cy = int(hand_world_landmarks.x),int(hand_world_landmarks.y)\n",
    "                lmList.append([id,cx,cy])\n",
    "        return(lmList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6712059a-a25b-46e6-870d-74109bfceacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this would be in main\n",
    "pTime = 0\n",
    "cTime = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,1280) # adjust width\n",
    "cap.set(4,960) # adjust height|\n",
    "\n",
    "detector = handDetector()\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img,1)\n",
    "    img.flags.writeable = False\n",
    "    img = detector.findHands(img)\n",
    "    lmlist = detector.findPosition(img)\n",
    "    rw_list = detector.findRealWorldPositions(img)\n",
    "    #Get FPS\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime - pTime)\n",
    "    pTime = cTime\n",
    "    \n",
    "    cv2.putText(img,str(int(fps)),(10,70),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,255),1)\n",
    "    if len(lmlist) != 0:\n",
    "        cv2.putText(img,f'Thumb: ({str(int(lmlist[4][1]))},{str(int(lmlist[4][2]))})',(10,100),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),1)\n",
    "        cv2.putText(img,f'Index: ({str(int(lmlist[8][1]))},{str(int(lmlist[8][2]))})',(10,130),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),1)\n",
    "        \n",
    "    \n",
    "    cv2.imshow(\"Webcam\", img) # This will open an independent window\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'): # quit when 'q' is pressed\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e14de0-4b56-4e3e-920a-0ced5b8f9d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945d583c-5416-4192-a8a3-5560a39deba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is using some simple package that handles image to photoimage conversion etc\n",
    "# window = tk.Tk()\n",
    "# window.title('Webcam Live Feed')\n",
    "# window.geometry('1300x500')\n",
    "# video = webcam.Box(window,width=450,height=450)\n",
    "# video.show_frames()\n",
    "\n",
    "# tk.mainloop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34d36df9",
   "metadata": {},
   "source": [
    "# Lets start building the App for the Demo\n",
    "\n",
    "Design goals: \n",
    "- Have Video stream from webcam\n",
    "- Have buttons to select which test (FTA or WRT)\n",
    "- Have buttons to start and stop data recording\n",
    "- will display live update of tests for each participant\n",
    "- Upon stop will populate or update the Table of average metrics\n",
    "\n",
    "Will try using Tkinter to design the application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f1b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 get the video capture object from the camera\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd2ca86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e65409c5d92ac8de6fbf37fa6262fc76ed77cb3927215706a6c6967fcf6f824"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
